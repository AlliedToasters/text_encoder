{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, activations\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "def byte_me(input_string):\n",
    "    \"\"\"Converts the input string to an array of\n",
    "    integers.\"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    b = bytearray()\n",
    "    b.extend(input_string.encode())\n",
    "    output = np.zeros(sl, dtype=np.uint8)\n",
    "    result = np.array(b)[:sl]\n",
    "    x = min(len(result), sl)\n",
    "    output[:x] = result\n",
    "    return output.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 64)     16384       input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 256), (None, 328704      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 256),  328704      embedding_5[1][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, None, 256)    65792       lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 739,584\n",
      "Trainable params: 739,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_seq2seq_lstm(num_encoder_tokens, latent_dim, num_decoder_tokens=None, emb_dim=64):\n",
    "    inp_char_embedder = Embedding(num_encoder_tokens, emb_dim)\n",
    "    \n",
    "    if num_decoder_tokens is not None:\n",
    "        outp_char_embedder = Embedding(num_decoder_tokens, emb_dim)\n",
    "    else:\n",
    "        outp_char_embedder = inp_char_embedder\n",
    "        num_decoder_tokens = num_encoder_tokens\n",
    "\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    embedded_encoder_inputs = inp_char_embedder(encoder_inputs)\n",
    "    encoder = LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(embedded_encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    embedded_decoder_inputs = outp_char_embedder(decoder_inputs)\n",
    "\n",
    "\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(embedded_decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    return model, encoder_states\n",
    "\n",
    "num_encoder_tokens = 256\n",
    "latent_dim = 256\n",
    "\n",
    "autoencoder, states = build_seq2seq_lstm(num_encoder_tokens, latent_dim)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00387643, 0.00391192, 0.00389487, ..., 0.00389812,\n",
       "         0.00390685, 0.00391295],\n",
       "        [0.00387639, 0.00389949, 0.00390452, ..., 0.00389897,\n",
       "         0.00390226, 0.00390655],\n",
       "        [0.00387394, 0.00390868, 0.00390311, ..., 0.00390289,\n",
       "         0.00390836, 0.00391922],\n",
       "        ...,\n",
       "        [0.00391605, 0.00390067, 0.003907  , ..., 0.00390029,\n",
       "         0.00390275, 0.00391897],\n",
       "        [0.00390654, 0.00388774, 0.00390362, ..., 0.00390388,\n",
       "         0.00390672, 0.00391707],\n",
       "        [0.00391581, 0.0038845 , 0.00390939, ..., 0.0039181 ,\n",
       "         0.00388666, 0.00392168]],\n",
       "\n",
       "       [[0.00387643, 0.00391192, 0.00389487, ..., 0.00389812,\n",
       "         0.00390685, 0.00391295],\n",
       "        [0.00387639, 0.00389949, 0.00390452, ..., 0.00389897,\n",
       "         0.00390226, 0.00390655],\n",
       "        [0.00387394, 0.00390868, 0.00390311, ..., 0.00390289,\n",
       "         0.00390836, 0.00391922],\n",
       "        ...,\n",
       "        [0.00391605, 0.00390067, 0.003907  , ..., 0.00390029,\n",
       "         0.00390275, 0.00391897],\n",
       "        [0.00390654, 0.00388774, 0.00390362, ..., 0.00390388,\n",
       "         0.00390672, 0.00391707],\n",
       "        [0.00391581, 0.0038845 , 0.00390939, ..., 0.0039181 ,\n",
       "         0.00388666, 0.00392168]]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '„Åça completely different example from the one I had been using before this allwent to shit'\n",
    "out = byte_me(string)\n",
    "\n",
    "out = np.concatenate([out, out])\n",
    "autoencoder.predict([out, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('many_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n",
    "df['lns'] = df['query'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.132663e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.034532e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.876606e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.418000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lns\n",
       "count  2.132663e+07\n",
       "mean   1.034532e+01\n",
       "std    6.876606e+00\n",
       "min    0.000000e+00\n",
       "50%    9.000000e+00\n",
       "99%    3.200000e+01\n",
       "max    1.418000e+03"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['lns']].describe(percentiles=[.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df['query'].dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = vals[:100000]\n",
    "rows = [byte_me(x) for x in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate(rows)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(X, test_size=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "charbank = 'abcdefghijklmnopqrstuvwxyz'\n",
    "charbank = charbank + charbank.upper()\n",
    "charbank = charbank + '0123456789'\n",
    "\n",
    "def deletion(string):\n",
    "    \"\"\"Performs a random deletion of input string\"\"\"\n",
    "    to_del = np.random.randint(0, high=len(string))\n",
    "    return string[:to_del] + string[to_del+1:]\n",
    "\n",
    "def insertion(string, charbank=charbank):\n",
    "    \"\"\"Performs a random insertion into input string\"\"\"\n",
    "    to_ins = np.random.randint(0, high=len(string))\n",
    "    char = np.random.choice(list(charbank))\n",
    "    return string[:to_ins] + char + string[to_ins:]\n",
    "\n",
    "def swap(string):\n",
    "    \"\"\"swaps two consecutive characters in string.\"\"\"\n",
    "    to_swap = np.random.randint(0, high=(len(string)-1))\n",
    "    return string[:to_swap] + string[to_swap+1] + string[to_swap] + string[to_swap+2:]\n",
    "\n",
    "def apply_noise(string):\n",
    "    \"\"\"Randomly applies one type of noise.\"\"\"\n",
    "    if len(string) < 2:\n",
    "        return string\n",
    "    func = np.random.choice([deletion, insertion, swap])\n",
    "    return func(string)\n",
    "\n",
    "def random_gen(batch_size=32):\n",
    "    \"\"\"\n",
    "    For training the identity function.\n",
    "    Generates random sequences.\n",
    "    \"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    while True:\n",
    "        X_out = np.random.randint(0, high=256, size=(batch_size, sl))\n",
    "        Y_out = np.array([to_categorical(x, num_classes=256) for x in X_out])\n",
    "        yield X_out, Y_out\n",
    "\n",
    "\n",
    "def data_gen(X, batch_size=32):\n",
    "    \"\"\"\n",
    "    For training the identity function on real queries.\n",
    "    Generates identity samples of queries.\n",
    "    \"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    while True:\n",
    "        idx = np.random.randint(len(X), size=(batch_size))\n",
    "        X_out = X[idx]\n",
    "        X_dec = np.zeros(shape=X_out.shape, dtype=X_out.dtype)\n",
    "        X_dec[:, 1:] = X_out[:, :-1]\n",
    "        Y_out = np.array([to_categorical(x, num_classes=256) for x in X_out])\n",
    "        yield [X_out, X_dec], Y_out\n",
    "        \n",
    "def noise_gen(X, batch_size=32):\n",
    "    \"\"\"\n",
    "    For training the identity function on real queries.\n",
    "    Generates identity samples of queries.\n",
    "    \"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    while True:\n",
    "        idx = np.random.randint(len(X), size=(batch_size))\n",
    "        X_out = X[idx]\n",
    "        Y_out = np.array([to_categorical(x, num_classes=256) for x in X_out])\n",
    "        X_ = []\n",
    "        for i, x in enumerate(X_out):\n",
    "            try:\n",
    "                x = bytearray(x).split(b'\\0',1)[0].decode()\n",
    "            except UnicodeDecodeError:\n",
    "                #remove examples where bad unicode.\n",
    "                Y_out = np.concatenate([Y_out[:i], Y_out[i+1:]], axis=0)\n",
    "                continue\n",
    "            x = apply_noise(x)\n",
    "            x = byte_me(x)\n",
    "            X_.append(x)\n",
    "        X1 = np.concatenate(X_)\n",
    "        X_dec = np.zeros(shape=X_out.shape, dtype=X_out.dtype)\n",
    "        X_dec[:, 1:] = X_out[:, :-1]\n",
    "        #todo: debug cases where len(x) != len(y)\n",
    "        if len(X_out) == len(Y_out):\n",
    "            yield [X1, X_dec], Y_out\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "trg = data_gen(train)\n",
    "teg = data_gen(val)\n",
    "gen = random_gen()\n",
    "ntrg = noise_gen(train)\n",
    "nteg = noise_gen(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 74, 111, 114, 100,  97, 110,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6633 - acc: 0.8264\n",
      "512/512 [==============================] - 84s 164ms/step - loss: 0.7925 - acc: 0.8014 - val_loss: 0.6633 - val_acc: 0.8264\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.4915 - acc: 0.8698\n",
      "512/512 [==============================] - 88s 172ms/step - loss: 0.5636 - acc: 0.8532 - val_loss: 0.4915 - val_acc: 0.8698\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3944 - acc: 0.8975\n",
      "512/512 [==============================] - 86s 168ms/step - loss: 0.4322 - acc: 0.8875 - val_loss: 0.3944 - val_acc: 0.8975\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3217 - acc: 0.9172\n",
      "512/512 [==============================] - 84s 163ms/step - loss: 0.3532 - acc: 0.9085 - val_loss: 0.3217 - val_acc: 0.9172\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.2757 - acc: 0.9290\n",
      "512/512 [==============================] - 82s 160ms/step - loss: 0.3005 - acc: 0.9222 - val_loss: 0.2757 - val_acc: 0.9290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe78d05c358>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identity step\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizers.Adam(lr=.001), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "autoencoder.fit_generator(\n",
    "    generator=trg,\n",
    "    validation_data=teg,\n",
    "    steps_per_epoch=512,\n",
    "    validation_steps=100,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115 101  99 115 105 115 114 105 110 116 115 104 101 101 101 101   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'secsisrintsheeee'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model, example='testthisthang'):\n",
    "    example = example\n",
    "    inp = byte_me(example)\n",
    "    inp2 = np.zeros(shape=inp.shape, dtype=inp.dtype)\n",
    "    inp2[:, 1:] = inp[:, :-1]\n",
    "    out = model.predict([inp, inp2])\n",
    "    out = np.argmax(out, axis=2).astype(np.uint8)\n",
    "    print(out)\n",
    "    return encode_output(out)\n",
    "\n",
    "def encode_output(array):\n",
    "    \"\"\"\n",
    "    encodes neural network output to unicode.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return bytearray(array).split(b'\\0',1)[0].decode()\n",
    "    except UnicodeDecodeError:\n",
    "        i = 1\n",
    "        while True:\n",
    "            try:\n",
    "                return bytearray(array).split(b'\\0',1)[0][:-i].decode()\n",
    "            except UnicodeDecodeError:\n",
    "                i+=1\n",
    "                \n",
    "test_model(autoencoder, 'test this string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  44/4096 [..............................] - ETA: 9:46 - loss: 0.2626 - acc: 0.9329"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-49060ec153ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#no noise\n",
    "\n",
    "autoencoder.fit_generator(\n",
    "    generator=trg,\n",
    "    validation_data=teg,\n",
    "    steps_per_epoch=4096,\n",
    "    validation_steps=42,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116 101 115 116  32 116 104 105 115  32 115 116 114 105 110 103  32 111\n",
      "  117 116  32 115 101 101  32 119 104  97 116  32 121 111]]\n",
      "[[ 69 101  42 118  32 184  67 239 115  32 115 180 114 105 110 103  55 111\n",
      "  117 116  32 107  97 139  48 158 104  97  66  32  29 111]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ee*v '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(autoencoder, 'test this string out see what you get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1795 - acc: 0.9525\n",
      "4096/4096 [==============================] - 625s 153ms/step - loss: 0.2270 - acc: 0.9403 - val_loss: 0.1795 - val_acc: 0.9525\n",
      "Epoch 2/100\n",
      "3833/4096 [===========================>..] - ETA: 40s - loss: 0.1389 - acc: 0.9628"
     ]
    }
   ],
   "source": [
    "#noise\n",
    "\n",
    "autoencoder.fit_generator(\n",
    "    generator=ntrg,\n",
    "    validation_data=nteg,\n",
    "    steps_per_epoch=4096,\n",
    "    validation_steps=42,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 2, 2, 0, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 0, 1, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 1,\n",
       "       0, 1, 0, 2, 0, 2, 0, 2, 2, 1, 0, 2, 2, 0, 2, 1, 2, 1, 2, 2, 1, 2,\n",
       "       0, 0, 1, 0, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 2, 2, 0, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(3, size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116 101 115 116  32 116 104 105 115  32 115 116 114 105 110 103  32 111\n",
      "  117 116  32 115 101 101  32 119 104  97 116  32 121 111]]\n",
      "[[ 84   1  97 116 116  32 105 105 112 115 112 115 105 105 110 103 103 116\n",
      "  114 116  32  32 104 104 114  32  32  97  97 101   0 101]]\n",
      "T\u0001att iipspsiinggtrt  hhr  aae\n",
      "[[105  97 114 109  97 120  32  51  54  53   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[ 97 105 114 109  97   1  32  51  53  53   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "airma\u0001 355\n",
      "[[103 105 118 101  32 109 101  32 107 114 105 101   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[103 105   1  98  32 109 101  32 101 114 101 101   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "gi\u0001b me eree\n"
     ]
    }
   ],
   "source": [
    "print(test_model(autoencoder, 'test this string out see what you get'))\n",
    "print(test_model(autoencoder, 'iarmax 365'))\n",
    "print(test_model(autoencoder, 'give me krie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
