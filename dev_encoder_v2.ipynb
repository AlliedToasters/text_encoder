{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, activations\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "def byte_me(input_string):\n",
    "    \"\"\"Converts the input string to an array of\n",
    "    integers.\"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    b = bytearray()\n",
    "    b.extend(input_string.encode())\n",
    "    output = np.zeros(sl, dtype=np.uint8)\n",
    "    result = np.array(b)[:sl]\n",
    "    x = min(len(result), sl)\n",
    "    output[:x] = result\n",
    "    return output.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 32, 64)            16384     \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 32, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 256)           8448      \n",
      "=================================================================\n",
      "Total params: 5,271,808\n",
      "Trainable params: 5,271,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sl = 32 #sequence length\n",
    "\n",
    "inp = layers.Input(shape=(sl,), dtype=tf.uint8)\n",
    "x = layers.Embedding(input_dim=256, output_dim=64, input_length=64)(inp)\n",
    "x = layers.Reshape((2048,))(x)\n",
    "#x = layers.Dropout(.2)(x)\n",
    "x = layers.Dense(1024, activation='softsign')(x)\n",
    "x = layers.Dense(1024, activation='softsign')(x)\n",
    "x = layers.Dense(1024, activation='softsign')(x)\n",
    "#x = layers.Dropout(.2)(x)\n",
    "x = layers.Dense(1024, activation='softsign')(x)\n",
    "x = layers.Reshape((32, 32))(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=1, activation=(lambda x: activations.softmax(x, axis=1)))(x)\n",
    "\n",
    "\n",
    "autoencoder = models.Model(inputs=inp, outputs=x)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03105543, 0.03188496, 0.0315535 , ..., 0.03190678,\n",
       "         0.03119541, 0.03067248],\n",
       "        [0.03149303, 0.03128268, 0.03171589, ..., 0.03093702,\n",
       "         0.03091418, 0.0308835 ],\n",
       "        [0.03106962, 0.03081398, 0.03052501, ..., 0.03119929,\n",
       "         0.03201878, 0.03141157],\n",
       "        ...,\n",
       "        [0.03154055, 0.03171684, 0.03163086, ..., 0.03081964,\n",
       "         0.03090471, 0.03054261],\n",
       "        [0.03135443, 0.03113623, 0.03108686, ..., 0.0311783 ,\n",
       "         0.03131009, 0.0312447 ],\n",
       "        [0.03110107, 0.03147691, 0.03189255, ..., 0.03142247,\n",
       "         0.03141307, 0.03184773]],\n",
       "\n",
       "       [[0.03105543, 0.03188496, 0.0315535 , ..., 0.03190678,\n",
       "         0.03119541, 0.03067248],\n",
       "        [0.03149303, 0.03128268, 0.03171589, ..., 0.03093702,\n",
       "         0.03091418, 0.0308835 ],\n",
       "        [0.03106962, 0.03081398, 0.03052501, ..., 0.03119929,\n",
       "         0.03201878, 0.03141157],\n",
       "        ...,\n",
       "        [0.03154055, 0.03171684, 0.03163086, ..., 0.03081964,\n",
       "         0.03090471, 0.03054261],\n",
       "        [0.03135443, 0.03113623, 0.03108686, ..., 0.0311783 ,\n",
       "         0.03131009, 0.0312447 ],\n",
       "        [0.03110107, 0.03147691, 0.03189255, ..., 0.03142247,\n",
       "         0.03141307, 0.03184773]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '„Åça completely different example from the one I had been using before this allwent to shit'\n",
    "out = byte_me(string)\n",
    "\n",
    "out = np.concatenate([out, out])\n",
    "autoencoder.predict(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('many_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n",
    "df['lns'] = df['query'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.132663e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.034532e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.876606e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.418000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lns\n",
       "count  2.132663e+07\n",
       "mean   1.034532e+01\n",
       "std    6.876606e+00\n",
       "min    0.000000e+00\n",
       "50%    9.000000e+00\n",
       "99%    3.200000e+01\n",
       "max    1.418000e+03"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['lns']].describe(percentiles=[.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df['query'].dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = vals[:1000000]\n",
    "rows = [byte_me(x) for x in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate(rows)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(X, test_size=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "charbank = 'abcdefghijklmnopqrstuvwxyz'\n",
    "charbank = charbank + charbank.upper()\n",
    "charbank = charbank + '0123456789'\n",
    "\n",
    "def deletion(string):\n",
    "    \"\"\"Performs a random deletion of input string\"\"\"\n",
    "    to_del = np.random.randint(0, high=len(string))\n",
    "    return string[:to_del] + string[to_del+1:]\n",
    "\n",
    "def insertion(string, charbank=charbank):\n",
    "    \"\"\"Performs a random insertion into input string\"\"\"\n",
    "    to_ins = np.random.randint(0, high=len(string))\n",
    "    char = np.random.choice(list(charbank))\n",
    "    return string[:to_ins] + char + string[to_ins:]\n",
    "\n",
    "def swap(string):\n",
    "    \"\"\"swaps two consecutive characters in string.\"\"\"\n",
    "    to_swap = np.random.randint(0, high=(len(string)-1))\n",
    "    return string[:to_swap] + string[to_swap+1] + string[to_swap] + string[to_swap+2:]\n",
    "\n",
    "def apply_noise(string):\n",
    "    \"\"\"Randomly applies one type of noise.\"\"\"\n",
    "    if len(string) < 2:\n",
    "        return string\n",
    "    func = np.random.choice([deletion, insertion, swap])\n",
    "    return func(string)\n",
    "\n",
    "def random_gen(batch_size=32):\n",
    "    \"\"\"\n",
    "    For training the identity function.\n",
    "    Generates random sequences.\n",
    "    \"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    while True:\n",
    "        X_out = np.random.randint(0, high=256, size=(batch_size, sl))\n",
    "        Y_out = np.array([to_categorical(x, num_classes=256) for x in X_out])\n",
    "        yield X_out, Y_out\n",
    "\n",
    "\n",
    "def data_gen(X, batch_size=32):\n",
    "    \"\"\"\n",
    "    For training the identity function on real queries.\n",
    "    Generates identity samples of queries.\n",
    "    \"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    while True:\n",
    "        idx = np.random.randint(len(X), size=(batch_size))\n",
    "        X_out = X[idx]\n",
    "        Y_out = np.array([to_categorical(x, num_classes=256) for x in X_out])\n",
    "        yield X_out, Y_out\n",
    "        \n",
    "def noise_gen(X, batch_size=32):\n",
    "    \"\"\"\n",
    "    For training the identity function on real queries.\n",
    "    Generates identity samples of queries.\n",
    "    \"\"\"\n",
    "    sl = 32 #sequence length\n",
    "    while True:\n",
    "        idx = np.random.randint(len(X), size=(batch_size))\n",
    "        X_out = X[idx]\n",
    "        Y_out = np.array([to_categorical(x, num_classes=256) for x in X_out])\n",
    "        X_ = []\n",
    "        for i, x in enumerate(X_out):\n",
    "            try:\n",
    "                x = bytearray(x).split(b'\\0',1)[0].decode()\n",
    "            except UnicodeDecodeError:\n",
    "                #remove examples where bad unicode.\n",
    "                Y_out = np.concatenate([Y_out[:i], Y_out[i+1:]], axis=0)\n",
    "                continue\n",
    "            x = apply_noise(x)\n",
    "            x = byte_me(x)\n",
    "            X_.append(x)\n",
    "        X_out = np.concatenate(X_)\n",
    "        #todo: debug cases where len(x) != len(y)\n",
    "        if len(X_out) == len(Y_out):\n",
    "            yield X_out, Y_out\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "trg = data_gen(train)\n",
    "teg = data_gen(val)\n",
    "gen = random_gen()\n",
    "ntrg = noise_gen(train)\n",
    "nteg = noise_gen(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4096/4096 [==============================] - 249s 61ms/step - loss: 2.5353\n",
      "Epoch 2/5\n",
      "4096/4096 [==============================] - 242s 59ms/step - loss: 1.7956\n",
      "Epoch 3/5\n",
      "4096/4096 [==============================] - 240s 59ms/step - loss: 1.5849\n",
      "Epoch 4/5\n",
      "4096/4096 [==============================] - 242s 59ms/step - loss: 1.5459\n",
      "Epoch 5/5\n",
      "4096/4096 [==============================] - 225s 55ms/step - loss: 1.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe72c424048>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identity step\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "autoencoder.compile(optimizer=optimizers.Adam(lr=.001), loss='categorical_crossentropy')\n",
    "autoencoder.fit_generator(\n",
    "    generator=gen,\n",
    "    steps_per_epoch=4096,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116 101 115 116  32 116 104 105 115  32 115 116 114 105 110 103   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[ 26  13 210 217  32  88 220 139 145 225 112 180 114  86 186 220   0   0\n",
      "    7   0 243  15   0  97   0  31  31  31   0   7 169 254]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\x1a\\r'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model, example='testthisthang'):\n",
    "    example = example\n",
    "    inp = byte_me(example)\n",
    "    print(inp)\n",
    "    out = model.predict(inp)\n",
    "    out = np.argmax(out, axis=2).astype(np.uint8)\n",
    "    print(out)\n",
    "    return encode_output(out)\n",
    "\n",
    "def encode_output(array):\n",
    "    \"\"\"\n",
    "    encodes neural network output to unicode.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return bytearray(array).split(b'\\0',1)[0].decode()\n",
    "    except UnicodeDecodeError:\n",
    "        i = 1\n",
    "        while True:\n",
    "            try:\n",
    "                return bytearray(array).split(b'\\0',1)[0][:-i].decode()\n",
    "            except UnicodeDecodeError:\n",
    "                i+=1\n",
    "                \n",
    "test_model(autoencoder, 'test this string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 8ms/step - loss: 0.5827\n",
      "4096/4096 [==============================] - 226s 55ms/step - loss: 0.6295 - val_loss: 0.5827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe72c4246d8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no noise\n",
    "\n",
    "autoencoder.fit_generator(\n",
    "    generator=trg,\n",
    "    validation_data=teg,\n",
    "    steps_per_epoch=4096,\n",
    "    validation_steps=42,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116 101 115 116  32 116 104 105 115  32 115 116 114 105 110 103  32 111\n",
      "  117 116  32 115 101 101  32 119 104  97 116  32 121 111]]\n",
      "[[ 69 101  42 118  32 184  67 239 115  32 115 180 114 105 110 103  55 111\n",
      "  117 116  32 107  97 139  48 158 104  97  66  32  29 111]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ee*v '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(autoencoder, 'test this string out see what you get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 1.1356\n",
      "4096/4096 [==============================] - 226s 55ms/step - loss: 1.3720 - val_loss: 1.1356\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.9698\n",
      "4096/4096 [==============================] - 249s 61ms/step - loss: 1.0325 - val_loss: 0.9698\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.9074\n",
      "4096/4096 [==============================] - 251s 61ms/step - loss: 0.9258 - val_loss: 0.9074\n",
      "Epoch 4/100\n",
      "1840/4096 [============>.................] - ETA: 2:19 - loss: 0.8756"
     ]
    }
   ],
   "source": [
    "#noise\n",
    "\n",
    "autoencoder.fit_generator(\n",
    "    generator=ntrg,\n",
    "    validation_data=nteg,\n",
    "    steps_per_epoch=4096,\n",
    "    validation_steps=42,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116 101 115 116  32 116 104 105 115  32 115 116 114 105 110 103  32 111\n",
      "  117 116  32 115 101 101  32 119 104  97 116  32 121 111]]\n",
      "[[  3 101 101 115 116  32 104 117 115   0 115 114 114 105 110 103  32 111\n",
      "  117 117 116 101 101 101  32  97 104 104 116 104 111 105]]\n",
      "\u0003eest hus\n",
      "[[105  97 114 109  97 120  32  51  54  53   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[  3 105   1 109  97 120  32  54  51   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "\u0003i\u0001max 63\n",
      "[[103 105 118 101  32 109 101  32 107 114 105 101   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[  3 105 118 101  32 109 101  32 107   1 114 101   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "\u0003ive me k\u0001re\n"
     ]
    }
   ],
   "source": [
    "print(test_model(autoencoder, 'test this string out see what you get'))\n",
    "print(test_model(autoencoder, 'iarmax 365'))\n",
    "print(test_model(autoencoder, 'give me krie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
