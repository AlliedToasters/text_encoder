{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, activations\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "def byte_me(input_string):\n",
    "    \"\"\"Converts the input string to an array of\n",
    "    integers.\"\"\"\n",
    "    b = bytearray()\n",
    "    b.extend(input_string.encode())\n",
    "    return np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 64, 64)            16384     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 62, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 30, 64)            12352     \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, None, 1920)        0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, None, 2048)        3934208   \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 64, 256)           8448      \n",
      "=================================================================\n",
      "Total params: 3,983,744\n",
      "Trainable params: 3,983,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = layers.Input(shape=(64,), dtype=tf.uint8)\n",
    "x = layers.Embedding(input_dim=256, output_dim=64, input_length=64)(inp)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu', strides=2)(x)\n",
    "\n",
    "x = layers.Reshape(target_shape=(-1, 1920))(x)\n",
    "#x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "#\"bottleneck\" layer\n",
    "#embedding = layers.Dense(256)(x)\n",
    "\n",
    "#x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(2048, activation='relu')(x)\n",
    "x = layers.Reshape((64, 32))(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=1, activation=(lambda x: activations.softmax(x, axis=1)))(x)\n",
    "\n",
    "\n",
    "autoencoder = models.Model(inputs=inp, outputs=x)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0156486 , 0.01561856, 0.01558934, ..., 0.01570393,\n",
       "         0.01559692, 0.01554755],\n",
       "        [0.01561294, 0.01559056, 0.01562465, ..., 0.01561609,\n",
       "         0.01559465, 0.01563474],\n",
       "        [0.01567719, 0.01556424, 0.01561314, ..., 0.01554751,\n",
       "         0.01562736, 0.01566313],\n",
       "        ...,\n",
       "        [0.0156566 , 0.01563647, 0.01561924, ..., 0.01566086,\n",
       "         0.01559545, 0.01555576],\n",
       "        [0.0155953 , 0.01571142, 0.01565355, ..., 0.01561982,\n",
       "         0.0156517 , 0.01562703],\n",
       "        [0.01552223, 0.01566094, 0.01563862, ..., 0.01564148,\n",
       "         0.01564958, 0.0156145 ]],\n",
       "\n",
       "       [[0.0156486 , 0.01561856, 0.01558934, ..., 0.01570393,\n",
       "         0.01559692, 0.01554755],\n",
       "        [0.01561294, 0.01559056, 0.01562465, ..., 0.01561609,\n",
       "         0.01559465, 0.01563474],\n",
       "        [0.01567719, 0.01556424, 0.01561314, ..., 0.01554751,\n",
       "         0.01562736, 0.01566313],\n",
       "        ...,\n",
       "        [0.0156566 , 0.01563647, 0.01561924, ..., 0.01566086,\n",
       "         0.01559545, 0.01555576],\n",
       "        [0.0155953 , 0.01571142, 0.01565355, ..., 0.01561982,\n",
       "         0.0156517 , 0.01562703],\n",
       "        [0.01552223, 0.01566094, 0.01563862, ..., 0.01564148,\n",
       "         0.01564958, 0.0156145 ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def byte_me(input_string):\n",
    "    \"\"\"Converts the input string to an array of\n",
    "    integers.\"\"\"\n",
    "    b = bytearray()\n",
    "    b.extend(input_string.encode())\n",
    "    output = np.zeros(64, dtype=np.uint8)\n",
    "    result = np.array(b)[:64]\n",
    "    x = min(len(result), 64)\n",
    "    output[:x] = result\n",
    "    return output.reshape(1, -1)\n",
    "\n",
    "string = 'きa completely different example from the one I had been using before this allwent to shit'\n",
    "out = byte_me(string)\n",
    "\n",
    "out = np.concatenate([out, out])\n",
    "autoencoder.predict(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('many_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df['query'].fillna('').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = ''.join(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3447357 chunks.\n"
     ]
    }
   ],
   "source": [
    "chunks = len(text)//64\n",
    "print('{} chunks.'.format(chunks))\n",
    "rows = []\n",
    "\n",
    "for i in range(chunks):\n",
    "    rows.append(byte_me(text[i*64:(i+1)*64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3447357, 64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate(rows)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(X, test_size=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def data_gen(X=train, batch_size=32):\n",
    "    while True:\n",
    "        idx = np.random.randint(len(X), size=(batch_size))\n",
    "        X_out = X[idx]\n",
    "        Y_out = np.array([to_categorical(x, num_classes=256) for x in X_out])\n",
    "        yield X_out, Y_out\n",
    "        \n",
    "trg = data_gen(train)\n",
    "teg = data_gen(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 237/4096 [>.............................] - ETA: 3:48 - loss: 0.3101"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2d3d27ad8a61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "autoencoder.compile(optimizer=optimizers.Adam(lr=.001), loss='categorical_crossentropy')\n",
    "autoencoder.fit_generator(\n",
    "    generator=trg,\n",
    "    validation_data=teg,\n",
    "    steps_per_epoch=4096,\n",
    "    validation_steps=42,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, example='testthisthang'):\n",
    "    example = example * 8\n",
    "    inp = byte_me(example)\n",
    "    out = model.predict(inp)[0]\n",
    "    out = np.argmax(out, axis=1)\n",
    "    print(out)\n",
    "    return encode_output(out)\n",
    "\n",
    "def encode_output(array):\n",
    "    \"\"\"\n",
    "    encodes neural network output to unicode.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return bytearray(array).decode()\n",
    "    except:\n",
    "        return bytearray([115] + array.tolist()).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116 101 115 116 116 104 105 115 116 104  97 110 103 116 101 115 116 116\n",
      " 104 105 115 116 104  97 110 103 116 101 115 116 116 104 105 115 116 104\n",
      "  97   2 103 116 101 115 116 116 104 105   0 116 104  97 110 103 116 101\n",
      " 115 116 116 104 105 115 116 104  97 111]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'t\\x00\\x00\\x00\\x00\\x00\\x00\\x00e\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00i\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00a\\x00\\x00\\x00\\x00\\x00\\x00\\x00n\\x00\\x00\\x00\\x00\\x00\\x00\\x00g\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00e\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00i\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00a\\x00\\x00\\x00\\x00\\x00\\x00\\x00n\\x00\\x00\\x00\\x00\\x00\\x00\\x00g\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00e\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00i\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00g\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00e\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00i\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00a\\x00\\x00\\x00\\x00\\x00\\x00\\x00n\\x00\\x00\\x00\\x00\\x00\\x00\\x00g\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00e\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00i\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00a\\x00\\x00\\x00\\x00\\x00\\x00\\x00o\\x00\\x00\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(autoencoder)\n",
    "#bytearray([116, 101, 115, 116, 116, 104, 105, 115, 116, 104, 97, 110, 103]).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115, 111, 109, 101,  32, 116, 101, 120, 116,  32, 104, 101, 114,\n",
       "        101,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byte_me('some text here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
